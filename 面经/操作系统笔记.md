# 操作系统笔记

## 磁盘空间分配的方式

连续分配、链接分配和索引分配

**连续分配**：每个文件在磁盘中占有连续的块，这样便于顺序访问和直接访问，磁盘寻道时间短。但这样需要事先知道文件分配空间的大小。

**链接分配**：每个文件是磁盘块的链表，可以充分利用磁盘空闲空间。但寻道时间较长，不支持直接访问。此外链表的指针也会占用空间。

**索引分配**：将指针聚集在一起，组成一个索引块。索引分配支持直接访问，并且没有外部碎片问题，因为磁盘的任何空闲块可以满足更多空间的请求。然而，索引分配确实浪费空间。索引块指针的开销通常大于链接分配的指针开销。考虑一下常见情况，即一个文件只有一块或两块。采用链接分配，每块只浪费一个指针的空间。采用索引分配，即使只有一个或两个指针是非空的，也必须分配一个完整的索引块。

这一点提出了一个问题：索引块应为多大？每个文件必须有一个索引块，因此需要索引块尽可能小。然而，如果索引块太小，它不能为大的文件存储足够多的指针。因此，必须采取一种机制，以处理这个问题。此目的的机制包括：

- 链接方案：一个索引块通常为一个磁盘块。因此，它本身能直接读写。为了支持大的文件，可以将多个索引块链接起来。例如，一个索引块可以包括一个含有文件名的头部和一组头 100 个磁盘块的地址。下一个地址（索引块的最后一个字）为 null（对于小文件），或者另一个索引块的指针（对于大文件）。
- 多级索引：链接表示的一种变种是，通过第一级索引块指向一组第二级的索引块，它又指向文件块。当访问一块时，操作系统通过第一级索引查找第二级索引块，再采 用这个块查找所需的数据块。这种做法可以持续到第三级或第四级，具体取决于最大文件大小。对于 4096 字节的块，可以在索引块中存入 1024 个 4 字节的指针。两级索引支持 1 048 576 个数据块和 4GB 的最大文件。
- 组合方案：用于基于 UNIX 的文件系统，将索引块的前几个（如 15）指针存在文件的 inode 中。这些指针的前 12 个指向直接块；即它们包含存储文件数据的块的地址。因此，小的文件（不超过 12 块）不需要单独的索引块。如果块大小为 4KB，则不超过 48KB 的数据可以直接访问。接下来的 3 个指针指向间接块。第一个指向一级间接块。一级间接块为索引块，它包含的不是数据，而是真正包含数据的块的地址。第二个指向二级间接块，它包含了一个块的地址，而这个块内的地址指向了一些块，这些块中又包含了指向真实数据块的指针。最后一个指针为三级间接块指针。图 5 显示了一个 UNIX 的 inode。

![UNIX的inode](http://c.biancheng.net/uploads/allimg/181112/2-1Q112104552123.gif)

采用这种方法，一个文件的块数可以超过许多操作系统所用的 4 字节的文件指针所能访问的空间。32 位指针只能访问 232 字节，或 4GB。许多 UNIX 和 Linux 现在支持 64 位的 文件指针。这样的指针允许文件和文件系统为数艾字节。ZFS 文件系统支持 128 位的文件 指针。

索引分配方案与链接分配一样在性能方面有所欠缺。尤其是，虽然索引块可以缓存在内存中，但是数据块可能分布在整个卷上。

有些系统将连续分配和索引分配组合起来：对于小文件（只有 3 或 4 块的）采用连续分配；当文件增大时，自动切换到索引分配。由于大多数文件较小，小文件的连续分配的效率又高，所以平均性能还是相当不错的。



## 什么是文件，文件描述符？

在Linux操作系统中，一切皆文件。为了将应用程序和文件对应，文件描述符应运而生。例如0表示标准输入，1表示标准输出，2表示标准错误。fd是非负整数。实际上它是一个索引值，指向内核为每个进程所维护的该进程打开的文件记录表。



## RAID技术

RAID 0： 将数据按照条带化进行组织。

RAID1：将数据镜像复制一份。

RAID1+0：将数据镜像并按照条带化组织。

RAID0+1：将数据按照条带化组织并对条带镜像。

RAID2：带海明校验。

RAID3：带奇偶校验，使用单块校验盘。

RAID4：它对数据访问是按磁盘来的。RAID3一次一横条，而RAID4一次一竖条。

RAID5：奇偶校验码存在于所有磁盘上，常用round-robin布局。

RAID6：有两种校验码，能容2错。

![RAID 0+1 和 RAID 1+0](http://c.biancheng.net/uploads/allimg/181109/2-1Q109160349241.gif)

RAID技术存在的问题：

RAID并不总是保证数据对操作系统和使用者是可用的。

例如，文件指针可能是错的，或文件结构内的指针可能是错的。如果没有正确恢复，则不完整的写入会导致数据损坏。一些其他进程也会偶然写出文件系统的结构。RAID 防范物理媒介错误，但不是其他硬件和软件错误。与软件和硬件错误一样，系统数据潜在危险也有许多。

Solaris ZFS 文件系统采用创新方法来解决这些问题，即采用校验和，这是用于验证数据完整性的一种技术。ZFS 维护所有块（包括数据和元数据）的内部校验和。这些校验和没有与正在进行校验的块放在一起；而是与块的指针放在一起（见图 3）

![ZFS校验所有的元数据与数据](http://c.biancheng.net/uploads/allimg/181109/2-1Q109160A9106.gif)

考虑一个信息节点（存储文件系统元数据的结构），带有数据指针。每个数据块的校验和位于 inode 内，如果数据有问题，则校验和会不正确，并且文件系统会知道它。如果数据是镜像的，有一个块具有正确的校验和，并且另有一个块具有不正确的校验和，那么ZFS会自动采用好的块来更新错误的块。


类似地，指向 inode 的目录条目具有 inode 的校验和。当访问目录时，inode 的任何问题会检测到。所有 ZFS 结构都会进行校验和，以便提供比 RAID 磁盘集或标准文件系统更高级别的一致性、错误检测和错误纠正。因为 ZFS 的整体性能非常快，校验和计算与额外块读-改-写周期的额外开销不是明显的。

大多数的 RAID 实现的另一个问题是缺乏灵活性。考虑一个具有 20 个磁盘的存储阵列，它分为 4 组，每组有 5 个磁盘。5 个磁盘的组为 RAID 级别 5。因此，有 4 个单独的卷，每个都有文件系统。但是如果文件太大以致于不适合 5 个磁盘的组，怎么办？如果另一个文件系统需要很少的空间，怎么办？如果事先已经知道这些因素，则可以正确分配磁盘和卷。然而，很多时候磁盘的使用和需求随时间而变化。

即使存储阵列允许 20 个磁盘的集合创建成一个大的 RAID 集，其他问题可能出现。多个各种大小的卷可以创建在这个集上。但是有的卷管理器不允许我们改变卷的大小。在这种情况下，会有与上述相同的不匹配文件系统大小的问题。有些卷管理器允许更改大小，但是有些文件系统不允许文件系统生长或收缩。卷可以更改大小，但是文件系统需要重建以利用这些改变。

ZFS 将文件系统管理和卷管理组合到一起，比这些功能的传统分开提供更强的功能。磁盘，或磁盘分区，通过 RAID 集组成存储池。每个池可以容纳一个或多个 ZFS 文件系统。整个池的可用空间可用于该池的所有文件系统。

![img](http://c.biancheng.net/uploads/allimg/181109/2-1Q109160P14c.gif)
