## 操作系统笔记

###进程、线程和协程之间的联系

|          | 进程                                                         | 线程                                           | 协程                                                         |
| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ------------------------------------------------------------ |
| 定义     | 资源调度的基本单位                                           | CPU调度的基本单位                              | 用户态轻量级线程，线程内部调度的基本单位                     |
| 切换情况 | 进程CPU环境（栈，寄存器，页表和文件句柄等）的保存以及新调度进程环境的设置。 | 保存和设置程序计数器，少量寄存器和栈的内容     | 先将寄存器的上下文和栈保存，再                               |
| 切换过程 | 用户态-》内核态-》用户态                                     | 用户态-》内核态-》用户态                       | 用户态                                                       |
| 调用栈   | 内核栈                                                       | 内核栈                                         | 用户栈                                                       |
| 并发性   | 不同进程之间实现并发，各自占用CPU时间片运行                  | 一个进程内部多个线程并发执行                   | 同一时间只能一个协程，而其它的协程处于休眠状态，适合对任务分时处理 |
| 系统开销 | 需要切换虚拟地址空间，切换内核栈和硬件上下文，系统开销很大。 | 切换时只需保存和设置少量寄存器内容，开销很小。 | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，开销最小 |
| 通信     | 进程之间的通信需要借助操作系统                               | 线程之间可以直接读写进程数据段，来进行通信     | 共享内存，消息队列                                           |



### 中断和异常有什么区别？外中断和内中断有什么区别？

异常也称**内中断**，陷入（trap）指**CPU内部处理事件**，是由于CPU执行特定指令时出现的非法情况。 比如除数为0，或者地址越界，虚存系统的缺页。对异常的处理依赖于程序运行的现场，并且不能被屏蔽，一旦出现要立即处理。

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-40-2.png)

中断通常称为**外中断**，来自于CPU执行指令以外的事件，比如设备I/O发出的中断，硬件故障中断。中断可以被屏蔽，也就是CPU可以选择不立即响应中断。

软中断是执行中断指令产生的，而硬中断是由外设引发的

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-40-1.png)

### 说一说你知道哪一些操作线程的函数？

`pthread_create`: 创建一个线程，返回0表示线程创建成功。例子

`pthread_t pthread_self()`获取进程id

`int pthread_join(pthread_t tid, void** retval)` 等待线程结束

`void pthread_exit(void *retval)` 结束线程

`int pthread_detach(pthread_t tid)` 主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中``pthread_detach(pthread_self())``，调用后和主线程分离，子线程结束时自己立即回收资源。

```c
#include <stdio.h>
#include <pthread.h>

//线程要执行的函数，arg 用来接收线程传递过来的数据
void *ThreadFun(void *arg)
{
    //终止线程的执行，将“http://c.biancheng.net”返回
    pthread_exit("http://c.biancheng.net"); //返回的字符串存储在常量区，并非当前线程的私有资源
    printf("*****************");//此语句不会被线程执行
}

int main()
{
    int res;
    //创建一个空指针
    void * thread_result;
    //定义一个表示线程的变量
    pthread_t myThread;

    res = pthread_create(&myThread, NULL, ThreadFun, NULL);
    if (res != 0) {
        printf("线程创建失败");
        return 0;
    }
    //等待 myThread 线程执行完成，并用 thread_result 指针接收该线程的返回值
    res = pthread_join(myThread, &thread_result);
    if (res != 0) {
        printf("等待线程失败");
    }
    printf("%s", (char*)thread_result);
    return 0;
}
```

### 	说一说你知道哪些进程有关的函数？

进程结构由以下几个部分组成：**代码段，堆栈段，数据段**。代码段是静态的二进制码，多个程序可以共享，父进程与子进程除了pid不一样，其它都一样。父进程通过fork产生一个子进程。

父进程与子进程通过**写时复制(Copy on Write)**技术共享页面，只有当子进程需要写入页面才进行复制。如果子进程想要运行自己的代码段，就需要execv().

`pid_t fork(void)`: 创建进程，返回一个非负整数，父进程返回子进程的pid，子进程返回0；

`void exit(int status)`: 结束进程；

`pid_t getpid(void)`: 获取进程pid；

`pid_t getppid(void)`: 获取父进程pid。

### 关于程序退出方式，你知道哪些？

正常退出方式有：return, _exit(), exit()

exit()其实是对_exit() 的一个封装，都会终止进程并做相关的首尾工作，最主要的区别是exit()会调用终止处理程序和清除I/O缓存。

return和exit的区别，exit是函数，有参数，执行完后控制权交还给OS，return 可以在函数中，调用后控制权返回给上一级函数，若是main函数，则返还给OS。

还有一些其它退出方式：

abort()，异常程序终止，同时发送SIGABRT给调用进程。

接能导致进程终止的信号，比如cltr+c()就是SIGINT信号.

### Linux的进程控制

- 进程地址空间

虚存为每个进程创造了一种独占系统内存空间的假象，通常分为用户空间和内核空间，一般用户空间包括代码段，数据段，BSS段，堆区，映射区和栈区。

- 进程控制块PCB（处理机）

  进程的调度实际就是内核选择相应的进程控制块，被选择的进程控制块中包含了一个进程基本的信息：

  1. 进程标识符；pid

  2. 处理机状态： 

     ① 通用寄存器；

     ② 指令计数器；

     ③ 程序状态字PSW；

     ④ 用户栈指针。

  3. 进程调度信息

     ① 进程状态；
     ② 进程优先级；
     ③ 进程调度所需的其它信息，它们与所采用的进程调度算法有关，比如，进程已等待CPU的时间总和、进程已执行的时间总和等；
     ④ 事件，指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。

  4. 进程控制信息

     ① 程序和数据的地址；
     ② 进程同步和通信机制，指实现进程同步和进程通信时必需的机制，如消息队列指针、信号量等，它们可能全部或部分地放在PCB中；
     ③ 资源清单，即一张列出了除CPU以外的、进程所需的全部资源及已经分配到该进程的资源的清单；
     ④ 链接指针，它给出了本进程(PCB)所在队列中的下一个进程的PCB的首地址。

- 上下文切换

  内核管理所有的进程控制块，而进程控制块记录了进程全部的状态信息。**每一次进程调度就是一次上下文切换**，**所谓的上下文其实就是当前进程的运行状态**，主要包括通用寄存器、指令计数器、程序状态字（PSW）、用户栈指针和内核数据结构（页表、进程表和文件表）等。一次完整的进程调度，比如用户态-》内核态-》用户态这样的过程。

### 关于**<u>进程调度</u>算法**你了解多少？

1. 先来先服务(FCFS)

   非抢占式的调度算法，按照请求的顺序进行调度。

2. 短业务优先(SJF)

   非抢占式的调度算法，按照运行时间最短的业务优先。

3. 最短剩余时间优先(SRTN)

   SJF的抢占式版本，如果新的进程的运行时间比当前进程剩余执行时间短，则发生抢占，挂起当前进程。

4. 时间片轮转

   所有进程按照FCFS排成一个队列，每次调度时将时间片分给队首进程。当时间片用完，就由计时器发出时间中断，调度程序便停止该进程执行，并把它送到队尾，同时继续执行下一个时间片。

   时间片过小，会导致调度频繁，时间片过大，又不能保证实时性。

5. 优先级调度

   为每个进程分配一个优先级，按照优先级进行调度。

6. 多级反馈队列Multilevel Feedback Queue Scheduling

   如果一个进程需要100个时间片，那么按照时间片轮转算法，需要调度100次。多级队列是设置了多个队列，每个队列的时间片大小都不相同，进程在第一个队列没执行完就会被放入第二个队列，每个队列的时间片大小不相等，通常按照1,2,4,8...这样的比例

### Linux下进程通信的方式

- 管道通信 pipe

  - 无名管道（内存文件）

    无名管道只能半双工通信，而且只能在拥有亲缘关系的进程进行，比如父子进程

  - 有名管道（FIFO文件）

    有名管道以FIFO文件的形式存在于文件系统中，这样即使没有亲缘关系的进程也可以进行通信。有名管道也是半双工。

- 信号量semaphore

  信号量是一个计数器，用来控制多个进程对共享资源的访问，他作为一种锁机制，通常用来控制不同进程对临界区资源访问的互斥和同步。

- 共享内存 shared memory

  共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与信号量，配合使用来实现进程间的同步和通信。或者叫“内存映射”。

- 消息队列 message queue ，MQ

  消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

  消息队列可以独立于读写进程存在，从而避免了FIFO中同步管道打开和关闭可能产生的困难。

  避免了FIFIO同步阻塞问题，不需要进程提供自己的同步方法。

  读进程可以根据消息类型进行接受，而不像FIFO默认选择接受。	

- 套接字socket

  用于不同机器间进程通信，在本地也可作为两个进程通信的方式。

- 信号signal

  用于通知接收进程某个事件已经发生，比如按下ctrl + C就是信号SIGKILL。通过kill -l 可以看到全部信号。

### Windows下进程通信的方式

大部分与Linux进程通信方式相似

1. 文件映射

把文件内容当作进程中的一块内存来对待。因此进程不需要使用文件I/O，使用简单的指针就可以访问文件内容。

2. 剪切板

剪贴板是一个非常松散的交换媒介，可以支持任何数据格式，每一格式由一无符号整数标识，对标准(预定义)剪贴板格式，该值是Win32 API定义的常量；对非标准格式可以使用Register Clipboard Format函数注册为新的剪贴板格式。利用剪贴板进行交换的数据只需在数据格式上一致或都可以转化为某种格式就行。但剪贴板只能在基于Windows的程序中使用，不能在网络上使用。

2. 邮件槽(Mailslot)

邮件槽(Mailslots)提 供进程间单向通信能力，任何进程都能建立邮件槽成为邮件槽服务器。其它进程，称为邮件槽客户，可以通过邮件槽的名字给邮件槽服务器进程发送消息。进来的消 息一直放在邮件槽中，直到服务器进程读取它为止。一个进程既可以是邮件槽服务器也可以是邮件槽客户，因此可建立多个邮件槽实现进程间的双向通信。

### 讲一下线程之间的通信方式？

Linux下主要有四种线程通信方式：

1. 信号
2. 条件变量：使用通知的方式解锁，与互斥锁配合使用
3. 锁：互斥锁、读写锁、自旋锁
4. 信号量

Windows下主要有三种方式：

1. 全局变量：当多个线程访问同一个变量时，需要加上volatile修饰，以防编译器对此变量进行优化。
2. Message消息机制：常用的Message通信的接口主要有两个：PostMessage和PostThreadMessage，PostMessage为线程向主窗口发送消息。而PostThreadMessage是任意两个线程之间的通信接口。
3. CEvent为MFC中的一个对象，可以通过对CEvent的触发状态进行改变，从而实现线程间的通信和同步，这个主要是实现线程直接同步的一种方法。

### 进程之间通信的函数你知道哪些？

##### [管道](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=管道)

- 无名管道
  - 无名管道特点：
    - 无名管道是一种特殊的文件，这种文件只存在于内存中。
    - 无名管道只能用于父子进程或兄弟进程之间，必须用于具有亲缘关系的进程间的通信。
    - 无名管道只能由一端向另一端发送数据，是半双工方式，如果双方需要同时收发数据需要两个管道。
  - 相关接口：
    - int pipe(int fd[2]);
      - fd[2]：管道两端用fd[0]和fd[1]来描述，读的一端用fd[0]表示，写的一端用fd[1]表示。通信双方的进程中写数据的一方需要把fd[0]先close掉，读的一方需要先把fd[1]给close掉。
- 有名管道：
  - 有名管道特点：
    - 有名管道是FIFO文件，存在于文件系统中，可以通过文件路径名来指出。
    - 有名管道可以在不具有亲缘关系的进程间进行通信。
  - 相关接口：
    - int mkfifo(const char *pathname, mode_t mode);
      - pathname：即将创建的FIFO文件路径，如果文件存在需要先删除。
      - mode：和open()中的参数相同。

##### [消息队列](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=消息队列)

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

##### [共享内存](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=共享内存)

进程可以将同一段共享内存连接到它们自己的地址空间，所有进程都可以访问共享内存中的地址，如果某个进程向共享内存内写入数据，所做的改动将立即影响到可以访问该共享内存的其他所有进程。

- 相关接口

  - 创建共享内存：int shmget(key_t key, int size, int flag);

    成功时返回一个和key相关的共享内存标识符，失败范湖范围-1。

    - key：为共享内存段命名，多个共享同一片内存的进程使用同一个key。
    - size：共享内存容量。
    - flag：权限标志位，和open的mode参数一样。

  - 连接到共享内存地址空间：void *shmat(int shmid, void *addr, int flag);

    返回值即共享内存实际地址。

    - shmid：shmget()返回的标识。
    - addr：决定以什么方式连接地址。
    - flag：访问模式。

  - 从共享内存分离：int shmdt(const void *shmaddr);

    调用成功返回0，失败返回-1。

    - shmaddr：是shmat()返回的地址指针。

- 其他补充

  共享内存的方式像极了多线程中线程对全局变量的访问，大家都对等地有权去修改这块内存的值，这就导致在多进程并发下，最终结果是不可预期的。所以对这块临界区的访问需要通过信号量来进行进程同步。

  但共享内存的优势也很明显，首先可以通过共享内存进行通信的进程不需要像无名管道一样需要通信的进程间有亲缘关系。其次内存共享的速度也比较快，不存在读取文件、消息传递等过程，只需要到相应映射到的内存地址直接读写数据即可。

##### [信号量](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=信号量)

在提到共享内存方式时也提到，进程共享内存和多线程共享全局变量非常相似。所以在使用内存共享的方式是也需要通过信号量来完成进程间同步。多线程同步的信号量是POSIX信号量，而在进程里使用SYSTEM V信号量。

- 相关接口

  - 创建信号量：int semget(key_t key, int nsems, int semflag);

    创建成功返回信号量标识符，失败返回-1。

    - key：进程pid。
    - nsems：创建信号量的个数。
    - semflag：指定信号量读写权限。

  - 改变信号量值：int semop(int semid, struct sembuf *sops, unsigned nsops);

    我们所需要做的主要工作就是串讲sembuf变量并设置其值，然后调用semop，把设置好的sembuf变量传递进去。

    struct sembuf结构体定义如下：

    ```C++
    struct sembuf{
        short sem_num;
        short sem_op;
        short sem_flg;
    };Copy to clipboardErrorCopied
    ```

    成功返回信号量标识符，失败返回-1。

    - semid：信号量集标识符，由semget()函数返回。
    - sops：指向struct sembuf结构的指针，先设置好sembuf值再通过指针传递。
    - nsops：进行操作信号量的个数，即sops结构变量的个数，需大于或等于1。最常见设置此值等于1，只完成对一个信号量的操作。

  - 直接控制信号量信息：int semctl(int semid, int semnum, int cmd, union semun arg);

    - semid：信号量集标识符。
    - semnum：信号量集数组上的下标，表示某一个信号量。
    - arg：union semun类型。

##### [辅助命令](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=辅助命令)

ipcs命令用于报告共享内存、信号量和消息队列信息。

- ipcs -a：列出共享内存、信号量和消息队列信息。
- ipcs -l：列出系统限额。
- ipcs -u：列出当前使用情况。



### 🤔Linux 下同步机制？

POSIX信号量：可以对进程进行同步或者对线程进行同步；

POSIX互斥锁+条件变量：只能用于线程同步。条件变量(**cond**)是在多线程程序中用来实现“等待--》唤醒”逻辑的常用的方法。



### 如果系统中具有快表后，那么地址的转换过程变成什么样了？

快表是一种特殊的寄存器，正式名称translation lookaside buffer, TLB。页表指出逻辑地址的页号和物理主存块号之间的对应关系。

由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。 因为局部性原理，–般来说快表的命中率可以达到90%以上。

>①CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。
>
>②如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表命中，则访问某个逻辑地址仅需一次访存即可。
>
>③如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此,若快表未命中，则访问某个逻辑地址需要两次访存(注意:在找到页表项后，应同时将其存入快表,以便后面可能的再次访问。但若快表已满，则必须按照-定的算法对旧的页表项进行替换)

![img](https://pic1.zhimg.com/80/v2-082d6a5934800a03e23e759771b77220_720w.jpg)

### 内存交换和内存覆盖有什么区别？

交换主要在不同进程之间进行。而覆盖在同一进程中。

两者都是扩充内存的方法。

覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序）， 因此可以把用户空间分成**一个固定区**和**若干个覆盖区**。将***\*经常活跃\****的部分放在***\*固定区\****，其余部分按调用关系***分段***。首先将那些**即将要访问**的段放入**覆盖区**，其他段放在**外存**中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。覆盖主要用于早期计算机。

交换（对换）的基本思想是：

---- 把处于**等待（阻塞）**状态（或在CPU调度原则下被剥夺运行权利）的程序（进程）从内存移到辅存（外存），把内存空间腾出来，这一过程又叫换出。把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。***\*中级调度\****（策略）就是釆用交换技术。交换主要用于现代计算机。

### 动态分区分配算法有哪些，可以分别说说吗？

1. 首次适应算法

每次都从**低地址**开始查找，找到第一个满足大小空闲分区。空闲分区以地址递增的顺序排列，每次分配内存时顺序查找空闲分区链，找到能满足要求的第一个空闲分区。

2. 最佳适应算法

**每次优先使用小空闲区**。我们将空闲区域按照其大小递增连接成一个链表，每次从头开始找到第一个满足要求的空闲区。

缺点：每次都利用小分区，会产生越来越多的内存碎片。

3. 最坏适应算法

**每次优先使用大的空闲区。**这样可以减小内存碎片，但当大进程进来的时候，没有内存可用了。

4. 邻近适应算法

每次从上一次分配区域的下一个分区开始搜索，同时将链表组织成循环链表。但它常常导致内存的末尾空间分裂成小碎片。

总结：首次适应算法，效果最好速度最快。

### 虚拟技术是什么？有哪些？

虚拟技术是把一个物理实体转换为多个逻辑实体的技术。

包括时分复用和空分复用技术两个大类。

时分复用：多个程序或者用户想访问同一资源。比如分时系统，多道程序技术。

空分复用，最典型的就是虚拟内存。

### 进程状态的切换你知道多少？

- 就绪状态Ready:等待调度
- 运行状态Running
- 等待状态Waiting：等待资源

![img](操作系统(阿秀版)/操作系统-13-1-更改版.png)

就绪-》运行：通过CPU调度获得CPU时间片。

运行-》就绪：时间片到。

运行-》等待：I/O或事件

等待-》就绪：获得I/O，内存，网络等资源。

### 一个c++程序从文本到结束状态，要经历几个过程？

要经历四个过程。

1. 预处理阶段，对源文件中的头文件以及宏进行替换，以及条件预编译指令，

   在Linux下生成.i文件

2. 编译阶段，把预处理阶段生成的.i或.ii文件进行词法分析，语法分析，语义分析等，生成相应的汇编文件.s；

3. 汇编阶段，将汇编文件转换为二进制码，生成.o(linux)或.obj(windows)可重定向目标文件。

4. 链接阶段，将目标文件和其所需要的库进行链接，生成可执行文件，.out(linux),.exe(windows).

### 讲一下静态链接和动态链接的区别？有什么特点？

静态链接：由链接器在链接时将库的内容加入到可执行文件中。将一个库或多个库的目标文件链接到可执行文件中。.a(linux),.lib(windows).

动态链接：**把链接这个过程推迟到运行时候再执行**，由操作系统加载库。.so(linux),.dll(windows).

静态链接优点：

- 代码装载速度块，
- 只需保证开发者电脑中有正确的.lib文件就行，不需要考虑用户机上有无.lib文件

缺点：生成的可执行文件体积大，容易造成空间浪费。

动态链接的优点：

- 生成的可执行文件体积更小
- 独立性强，代码耦合度小，适合大规模软件开发
- 动态链接文件和可执行文件独立，极大降低代码维护的难度

缺点：客户机必须有动态链接文件才能运行，此外速度比静态链接慢。

### 通过例子讲一下从逻辑地址到物理地址的过程

可以通过页表将逻辑地址转换为物理地址。

1. 根据逻辑地址计算出，页号和业页内偏移量，
2. 判断页号是否越界
3. 查询页表找到页号对应的块号
4. 通过内存块号和页内偏移量得到物理地址

注意：页面大小通常是2的整数次幂。

逻辑地址=页号+页内地址

物理地址=块号+块内地址

5. 访问主存单元

### 进程同步的四种方法

1. 临界区(critical area)

对临界区资源访问的那段代码称为临界区；

为了进行互斥访问，需要先进行检查.

2. 同步和互斥

同步：多个进程因为合作有相互制约关系，有特定的执行顺序。例如生产者-消费者，哲学家进餐问题。

互斥：一个公共资源一次只允许一个进程访问。例如打印机，读者-写者。

3. 信号量

信号量是整型变量，有两种操作，V和P对应于加减操作：

- 当信号量大于0，调用P进行减一，当信号量等于0，进程睡眠
- 当信号量小于0，调用V进行加1，

P（或Wait()），V是原语（或Signal()）均为原子操作，不可分割，通常会屏蔽中断。

如果信号量只能等于0，1，那么就是互斥量。分别表示解锁和上锁。

### 如何使用信号量实现生产者-消费者模型？

问题描述：生产者往缓冲区填入数据，消费者从缓冲区取出数据。同时若缓冲区已满，则无法继续生产；缓冲区为空，则无法继续消费。

伪代码如下：

```
typedef int semaphore;
semaphore mutex = 1;//生产-消费是互斥过程
semaphore limit = N;//缓冲区上限
semaphore buff = 0;//缓冲区初始化为0
void producer(){
	while(true){
		P(limit)//A
		P(mutex)//B
		produce()
		V(mutex)
		V(buff)
	}
}

void customer()
{
	while(true){
		
		P(buff)
		P(mutex)
		consume()
		V(mutex)
		V(limit)
		
	}
}
```

上述的代码A，B两行是否能互换，为什么？

不能互换，否则容易生成死锁，当缓冲区满了之后，如果P(mutex)在前面，那么生产者仍能进入临界区，但此时需要满足P(limit)也就是缓冲区不满，但消费者不能进入临界区消费，导致生产者和消费者互相等待，造成死锁。

4. 管程 Monitor

管程将控制代码独立出来，更容易调用。

管程一次只允许一个进程使用管程，它是信号量的一种改进手段，管程引用了**条件变量**以及相关操作：wait()和signal()来实现同步操作，wait()适用于将进程阻塞，把管程让出来给另一个进程使用，而signal()则是唤醒阻塞的进程来使用管程。

```
monitor monitor name
{
    /* shared variable declarations */
    function P1 (...) {
        ...
    }
    function P2 (...){
        ...
    }
    .
    .
    .
    function Pn ( . . . ) {
        ...
    }
    initialization_code (...){
        ...
    }
}
```



### 操作系统如何进行内存管理

- 操作系统负责内存空间的分配与回收
- 操作系统需要对内存进行逻辑上的扩充，比如虚拟内存
- 操作系统需要提供地址转换功能
- 操作系统需要提供内存保护，各进程之间的运行是独立的



### 多道程序设计？

允许多个程序或进程进入内存中交替运行，在宏观上是并发执行，而在微观上是串行。

### 如何解决哲学家进餐问题？

若干哲学家围绕一个圆形饭桌就座，哲学家只有两种活动：吃饭和思考。吃饭的时候需要同时拿起叉子和勺子才能进食。且相邻的哲学家共用一个叉子或勺子。

思路： 为了避免死锁产生，我们设置两个条件：

1. 相邻的哲学家不能同时吃饭
2. 必须同时拿起左右手的餐具才能进餐

有三种策略可供参考

1. 最多只允许N-1个哲学家同时进餐

```
#define N 5//哲学家的数量
semaphore tableware[N];//第i个餐具的信号量
#define thinking 0
#define eating 1
semaphore limit = 4;//最多允许同时进餐的人数
void philosopher(int i){
	think();
	P(limit)
	P(tableware[i%N]);//请求左手的餐具
	P(tableware[(i+1)%N]);//请求右手的餐具
	eat()
	V(tableware[i%N]);//释放左手的餐具
	V(tableware[(i+1)%N]);//释放右手的餐具
	V(limit)
}
```

2. 仅当左右餐具都可以用时才进餐

```
#define N 5//哲学家的数量
semaphore tableware[N];//第i个餐具的信号量
#define thinking 0
#define eating 1
semaphore mutex = 1;//保护信号量
void philosopher(int i){
	think();
	P(mutex);
	P(tableware[i%N]);//请求左手的餐具
	P(tableware[(i+1)%N]);//请求右手的餐具
	V(mutex);
	eat()
	V(tableware[i%N]);//释放左手的餐具
	V(tableware[(i+1)%N]);//释放右手的餐具
}
```

3. 奇数哲学家总是先拿左手餐具再拿右手餐具，偶数哲学家则刚好相反

```
#define N 5//哲学家的数量
semaphore tableware[N];//第i个餐具的信号量
#define thinking 0
#define eating 1
semaphore limit = 4;//最多允许同时进餐的人数
void philosopher(int i){
	if(i & 1)
	{
        think();
        P(tableware[(i+1)%N]);//请求右手的餐具
        P(tableware[i%N]);//请求左手的餐具
        eat()
        V(tableware[(i+1)%N]);//释放右手的餐具
        V(tableware[i%N]);//释放左手的餐具
    }
    else{
    	think();
        P(tableware[i%N]);//请求左手的餐具
        P(tableware[(i+1)%N]);//请求右手的餐具
        eat()
        V(tableware[i%N]);//释放左手的餐具
    	V(tableware[(i+1)%N]);//释放右手的餐具
   }
}
```



### 如何解决读者写者问题？

读者写者问题又称为多读单写问题。多个读进程可以并发，但读和写互斥，只有写进程完成之后才能读。这意味着最后一个读进程要解除锁。

一个数据变量count用于记录同时读操作的数目，count_mutex用于对count加锁。

```
#define reader N//the number of readers
#define writer 1//the number of writer
int count = 0;//the variable for writing
semaphore RD_mutex = 1;
semaphore WR_mutex = 1;
void read(){
	P(RD_mutex);
	count++;
	if(count == 1){ P(WR_mutex); }//第一个读者对写加锁
	V(RD_mutex);
	_read()...
	P(RD_mutex);
	count--;
	if(count == 0){ V(WR_mutex); }//最后一个读者释放写锁
	V(RD_mutex);
	
}
void write(){
	P(WR_mutex);
	count ++;
	V(WR_mutex);
}
```

### 介绍几种典型的锁？

1. 读写锁

   也称多读单写，适合某个变量或资源需要同时读，单次写，且读写互斥（写优先于读）的场景。sync.RWmutex

2. 互斥锁

   同一时间只有一个进程能获得互斥锁，其它进程只有等待。由于互斥锁涉及到线程状态的切换，即从运行状态变为阻塞状态，因此需要由操作系统管理，涉及到进程的上下文切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁。

3. 条件变量

   互斥锁的一个明显的缺陷在于它只有两种状态——上锁和解锁。**条件变量则通过允许线程阻塞和等待其它进程发来信号的方法弥补了互斥锁的不足**。条件变量经常和互斥锁一起使用来避免出现【竞态条件】。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说，**互斥锁用于进程的互斥，而条件变量用于进程的同步**。

4. 自旋锁

   自旋锁是当一个进程发现它申请的资源被锁住，会周期地不断的尝试申请获得锁。这种循环等待的策略就是自旋锁spinlock。自旋锁可以避免进程上下文切换的开销。但是长时间上锁，自旋锁就很消耗性能，阻止了其它线程的运行和调度。一般会设置一个自旋时间，到达一定时间后让自旋锁自动释放。

### 如何回收线程？有哪几种方法？

- **等待线程结束：**int pthread_join(pthread_t tid, void** retval);

  主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。

  - tid：创建线程时通过指针得到tid值。
  - retval：指向返回值的指针。

- **结束线程：**pthread_exit(void *retval);

  子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。

  - retval：同上。

- **分离线程：**int pthread_detach(pthread_t tid);

  主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。

  - tid：同上。

### 如何让进程在后台运行？

https://www.cnblogs.com/jiangzhaowei/p/8971265.html

1. nohup

2. setsid

3. 在结尾加上&

4. disown

   答案就是用 **Ctrl-z**了！
    *在我们的日常工作中，我们可以用 CTRL-z 来将当前进程挂起到后台暂停运行，执行一些别的操作，然后再用 fg 来将挂起的进程重新放回前台（也可用 bg 来将挂起的进程放在后台）继续运行。这样我们就可以在一个终端内灵活切换运行多个任务，这一点在调试代码时尤为有用。因为将代码编辑器挂起到后台再重新放回时，光标定位仍然停留在上次挂起时的位置，避免了重新定位的麻烦。*

5. screen

查看多个在后台运行的进程：jobs -l， 将一个在后台运行的进程变为继续执行 bg %jobnum. 反过来就是fg %jobnum.

### Malloc申请内存时，系统会怎么做？

从操作系统层次上，malloc是通过两个系统调用实现的：brk和mmap。

- brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小，这样可以扩大进程在虚拟内存中堆的大小。

- mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内存。

通常，分配的内存小于128k时，通过brk调用来获得虚拟内存。

大于128k时，通过mmap来获得虚拟内存。

进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，通过缺页中断，让内核分配相应的物理内存，这样内存分配才完成。

### 守护进程、僵尸进程和孤儿进程

守护进程：

指在后台运行，没有控制终端与之相连的进程，周期性的执行某一个任务。Linux大多数服务就是通过daemon进行，如web的http。

（1）让程序在后台执行。方法是调用fork（）产生一个子进程，然后使父进程退出。

（2）调用setsid（）创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid（）使进程成为一个会话组长。setsid（）调用成功后，进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。

（3）禁止进程重新打开控制终端。经过以上步骤，进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过fork（）创建新的子进程，使调用fork的进程退出。

（4）关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符。

（5）将当前目录更改为根目录。

（6）子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，使用unmask（0）将屏蔽字清零。

（7）处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程（zombie），从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，子进程结束时不会产生僵尸进程。

孤儿进程：

如果父进程先于子进程退出，则子进程变为孤儿进程。此后孤儿进程将被init（进程号为1）收养，完成状态收集和退出工作。

僵尸进程

如果子进程先退出，子进程必须等到父进程捕捉到子进程结束状态才算正常退出，否则子进程将变为僵尸进程。

设置僵尸进程的**目的**是维护子进程的信息，以便父进程在以后某个时间点获取，包括进程pid，终止状态等。所以当终止子进程的父进程调用wait或waitpid时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）。



#### 如何避免僵尸进程？

- 通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN);表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。
- 父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回。
- 如果父进程很忙可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出。
- 通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，孙进程结束后，init会等待回收。

第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。



### 你知道局部性原理吗？各自有什么特点？

分为**时间局部性**和**空间局部性**。

时间局部性：程序执行代码以后，在一定时间后再次执行；如果数据被访问过，在一定时间后再次被访问；比如循环语句。

空间局部性：指访问的数据在内存中是连续存放的，比如数组。



### 什么是作业？它和进程有什么关系？

shell分前后台来控制的不是进程而是作业（job）或者进程组（PG）。一个前台作业可以由多个进程组成，一个后台作业也可能由多个进程组成。shell可以运行一个前台作业和多个后台作业。

**为什么只能运行一个前台作业？**

我们在前台新启动了一个作业，那么shell就被放到后台，因此shell就无法继续接收指令并解析运行。

作业和进程组的区别：如果作业中某个进程创建了子进程，那么这个子进程是不属于作业的。一旦作业结束，shell就会把自己提到前台，如果子进程还没有终止，那么它将自动变为后台进程组。



### 什么是会话？

会话一个或多个进程组的集合。一个会话可以有一个控制终端。在Xshell或WinSCp打开一个窗口就是新建一个会话。



### 如何知道在Linux/Windows平台下栈空间的大小。

Linux下由操作系统决定，可以通过ulimit -a 来查看，通过ulimit -s来设置。

Windows下一般由编译器决定。



### 🤔程序从堆中动态分配内存，虚拟内存是怎么操作的？

在进行动态内存分配时，例如malloc()函数或者其他高级语言中的new关键字，操作系统会在硬盘中创建或申请一段虚拟内存空间，并更新到页表（分配一个页表条目PTE，使该PTE指向硬盘上这个新创建的虚拟页），通过PTE建立虚拟页和物理页之间的关系。



### 什么是交换空间？

Linux 中交换空间在物理内存被用尽时使用，内存中不活跃的页会被置换出去。交换空间位于硬盘驱动器上， 交换空间的总大小应该相当于你的计算机内存的两倍和 32 MB这两个值中较大的一个，但是它不能超过 2048MB（2 GB）。



### 什么是抖动？

指页面的频繁调度现象，如刚进内存的页面被调出去。产生抖动的原因是分配给进程的物理块不够。



### 栈上分配内存和堆相比哪个快？

从两方面来考虑：

- 分配和释放，堆在分配和释放时都要调用函数（malloc,free)，比如分配时会到堆空间去寻找足够大小的空间（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。

- 访问时间，访问堆的一个具体单元，需要两次访问内存，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。

  

### 常见的内存分配错误有哪些？

1）内存分配未成功，却使用了它

2）内存分配成功，但未初始化

3）在非法地址操作指针

4）忘记释放内存，导致内存泄漏

5）释放了内存，却再次使用

6）尝试修改常量区的值或者常量指针，比如修改一个常量区的字符串



### ASCII，Unicode，UTF-8, UTF-16的区别？大端和小端知道吗？

ASCII 只有127个字符，表示英文字母的大小写、数字和一些符号，但由于其他语言用ASCII 编码表示字节不够，例如：常用中文需要两个字节，且不能和ASCII冲突，中国定制了GB2312编码格式，相同的，其他国家的语言也有属于自己的编码格式。

Unicode就是将这些语言统一到一套编码格式中，通常两个字节表示一个字符，而ASCII是一个字节表示一个字符，这样如果你编译的文本是全英文的，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。

UTF-8 是unicode的“**可变长编码**”版本， UTF-8编码将Unicode字符按数字大小编码为1-6个字节，英文字母被编码成一个字节，常用汉字被编码成三个字节，如果你编译的文本是纯英文的，那么用UTF-8就会非常节省空间，并且ASCII码也是UTF-8的一部分。

UTF-16,任何字符都用两个字节来存储，处理起来比较快。UTF-16能表示的字符总数65536，而Unicode 5.0收录的字符数已经达到99024，因此UTF-16不能容纳这么多字符。此外UTF-16存在大端，小端的问题，也就是字节顺序，其中：

- 大端模式(big-endian)，高字节放在内存低的地址。
- 小端模式(little-endian)，高字节放在内存高的地址。

区别和联系：

(1) 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码

(2) 用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件。

(3) 浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器.



#### 原子操作是如何实现的？

**处理器通过对缓存加锁或者总线加锁来实现多处理器之间的原子操作**。

**所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。**

所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能使用同时缓存i的缓存行。**



### 你说一说<u>页置换</u>算法有哪些？

1. 最佳置换算法（OPT）

   每次淘汰的页面是以后最长未使用的页面。虽然这个算法理论上可以得到最低的缺页率，但在工程上无法实现，因为无法预测之后访问页面的顺序。它常常作为其它页面置换算法的参照。

2. 先进先出（FIFO）

   每次淘汰的页面是最早进入内存的页面。FIFO性能较差，因为最先进入内存的页面也有可能访问最频繁。采用FIFO算法时，如果对—个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。

   ![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-57-2.png)

3. 最久未被使用置换算法LRU

   least recently used。该算法记录每个页面自上次被访问后所经历的时间片的数量，当发生缺页中断时，淘汰最久未被访问的页面。需要专门的硬件支持，开销比较大。

   ![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-57-4.png)

4. 时钟置换算法CLOCK

   为了解决LRU硬件开销大的问题，提出了CLOCK算法。它为每个页面设置一个访问位，初始化为0，再将内存中的页面都通过链表构成一个循环队列，CLOCK算法像时钟一样扫描这个队列。当某一页被访问时，将其访问位置1。当需要淘汰一个页面，只需从头检查各节点的访问位，如果是1，则将它置0；否则换出该页面。

若某一时刻所有的访问位为1，那么将所有访问位置0。因此置换一个页面最多经历两轮扫描。

此外还有时钟置换算法的改进。事实上，如果被淘汰的页面没有被修改过,就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。

### 😀什么是文件，文件描述符？

在Linux操作系统中，一切皆文件。为了将应用程序和文件对应，文件描述符应运而生。例如0表示标准输入，1表示标准输出，2表示标准错误。fd是非负整数。实际上它是一个索引值，指向内核为每个进程所维护的该进程打开的文件记录表。

### 😀你说一下缓存置换算法有哪些？

包括LRU, LFU, FIFO, ARC, MRU。

- 最久未被使用算法LRU

least recently used。每次淘汰最久未被使用的页面。需要专门的硬件，开销较大。

- 最不经常使用置换算法LFU

least frequently used。LFU将页面按照访问的频次进行排序，优先淘汰访问频次低的。如果频次最低的页面不止一种。我们要选择淘汰最老的页面。如果一个页面开始有很高的访问频率但后面很少访问，该算法就不够灵活。

- 先进先出FIFO

是一种绝对公平的方式，但容易导致效率降低。因为先进入队列的请求可能经常被访问，这样做会导致经常被访问的页面被置换到内存或磁盘上，很快就发生缺页中断，降低效率。

- 自适应缓存替换算法ARC

Adaptive replacement cache。该算法结合了LRU和LFU的优势。当访问的数据趋于访问最近的内容，会更多的访问LRU List，这样会增加LRU的空间；当数据趋向于访问最频繁的内容，会更多地命中LFU。

具体来说，

1. 整个cache分为两个部分，LRU和LFU各占一半，后续会自动调整partition，除此之外还分别有为它们服务的ghost list。

![img](https://pic1.zhimg.com/80/v2-11f663696444c6abe4a36d33b7fecf60_720w.jpg)

2. 在缓存中查找客户端要访问的数据，如果没有命中，需要从磁盘或者内存中取出，放在LRU链表头部。如果命中，且LFU链表中没有，则将数据放入LFU链表的头部，所有LRU链表的数据至少要被访问两次才会进入LFU链表。如果命中，且LFU链表中存在，则将数据重新放到LFU链表的头部。这么做，那些真正被频繁访问的页面将永远呆在缓存中，不经常访问的页面会向链表尾部移动，最终被淘汰出去。

![img](https://pic2.zhimg.com/80/v2-172e0f6a28b37179ac5d5a4292d27975_720w.jpg)

3. 如果此时缓存满了，则从LRU链表中淘汰链表尾部的数据，将数据的key放入LRU链表对应的ghost list。然后再在链表头部加入新数据。如果ghost list中的元素满了，先按照先进先出的方式来淘汰ghost list中的一个元素，然后再加入新的元素。

![img](https://pic4.zhimg.com/80/v2-10a66257629a1d01260b4d1022a0b187_720w.jpg)

如果没有命中的数据key处于ghost list中，则表示是一次幽灵（phantom）命中，系统知道，这是一个刚刚淘汰的页面，而不是第一次读取或者说很久之前读取的一个页面。ARC用这个信息来调整它自己，以适应当前的I/O模式（workload）。这个迹象说明我们的LRU缓存太小了。在这种情况下，LRU链表的长度将会被增加1，并将命中的数据key从ghost list中移除，放入LRU链表的头部。显然，LFU链表的长度将会被减少1。

同样，如果一次命中发生在LFU ghost 链表中，它会将LRU链表的长度减一，以此在LFU 链表中加一个可用空间。

![img](https://pic2.zhimg.com/80/v2-d1de2bdf8cd40186d80f2e3bd41a5e01_720w.jpg)

![img](https://pic2.zhimg.com/80/v2-03716cf44ef0fdea028a41ae9808a57d_720w.jpg)



- 2Q

two queues。 两个缓存队列，一个是FIFO另一个是LRU。当页面第一次被访问时，加入到FIFO队列中，当数据第二次被访问，将页面从FIFO移到LRU，同时按照各自的方式淘汰页面。

![img](https://upload-images.jianshu.io/upload_images/285001-b682bd0f45175a69.png?imageMogr2/auto-orient/strip|imageView2/2/w/370/format/webp)

## 死锁问题

定义：死锁是指两个或两个以上的**进程**在执行过程中，由于**竞争资源**或者由于**彼此通信**而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

产生条件：

1. **互斥条件**，指两个进程无法共享使用资源，如果一个在使用，另一个必须等待这个使用完。

2. **不可剥夺条件**，指一旦进程使用资源，就无法抢占式的获得资源。只能等使用进程释放。
3. **请求和保持条件**，进程拥有一种资源，但又申请另外的资源，且在申请成功之前不会释放当前进程占用的资源。
4. **循环等待条件**，存在资源的循环等待链，资源链上每个进程都得不到资源。

解决方案：

​	**死锁预防**：通过设置某些限制条件，破坏死锁产生的条件；

​	**死锁的避免**：系统对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源；如果分配后系统可能发生死锁，则不予分配，否则予以分配。这是一种保证系统不进入死锁状态的动态策略。

​	死锁检测和解除：

先检测：这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进入不安全区，此方法允许系统在运行过程中发生死锁。但可通过系统所设置的检测机构，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源。检测方法包括定时检测、效率低时检测、进程等待时检测等。

然后解除死锁：采取适当措施，从系统中将已发生的死锁清除掉。恢复策略包括：

- 抢占式的恢复
- 利用回滚恢复
- kill进程恢复

这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于[阻塞状态](https://baike.baidu.com/item/阻塞状态)的进程，使之转为[就绪状态](https://baike.baidu.com/item/就绪状态)，以继续运行。死锁的检测和解除措施，有可能使系统获得较好的资源利用率和吞吐量，但在实现上难度也最大。

​	死锁消极解法：因为解决死锁的代价很高，如果不采用任何措施（鸵鸟策略）会获得更高的性能，大多数操作系统都采用这种策略。





### 😀银行家算法

银行家算法由Dijkstra提出，它的目的是保证系统动态分配资源后是资源安全的，不会产生死锁。

比如我们现在有一组进程按照顺序，{P0,P1,P2,....Pn}执行。如果每个进程都能顺利执行，那么称此时系统的状态为安全状态，否则称为不安全状态。

银行家算法规定了如下的数据结构：

- 可用资源向量Available表示系统中各类资源的当前可用数目；
- 分配矩阵Allocate，每个进程对资源的当前占有量；
- 需求矩阵Need，它记录了每个进程当前对各类资源的申请量，等于最大需求矩阵与分配矩阵之差；
- 请求向量request，它记录了某个进程当前对各类资源的申请量，是银行家算法的入口参数；

银行家算法描述如下：

1. 如果request_i > Need_i，则进程P出错；

2. 如果request_i>available_i,则进程P阻塞；

3. 系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值
   　　　　Available[j] = Available[j] - Requesti[j];
   　　　　Allocation[i,j] = Allocation[i,j] + Requesti[j];
   　　　　Need[i,j] = Need[i,j] - Requesti[j];
   
4. 系统进行安全性检查，检查此次资源分配后系统是否安全，若安全才完成本次分配；否则本次分配作废，让P_i进程等待。

   这个安全性检查其实就是判断是否进程安全的过程，如果找到就返回true。 我们定义：

   - 工作向量work，记录系统中各类只要当前可用数目，它是available的替身；

   - 进程可完成标志向量finish;

     i. 初始化work = available, finish=[false]

     ii. 若按照进程编号找到一个可以加入安全序列的进程，则假设该进程不久将完成任务归还资源

     ​	work = work + allocation

     ​	finish_i = true

     iii. 否则， 若所有进程的可完成标志finish为真，则返回逻辑真，表示安全，否则返回false。

### 😀内存分配方式？

**内存为程序分配空间有四种分配方式：**

1、连续分配方式

2、基本分页存储管理方式

3、基本分段存储管理方式

4、段页式存储管理方式

### 什么是内部碎片和外部碎片？

内部碎片：已经被分配出去（能明确指出是哪个进程），但无法被利用的空间；一般常见于固定分配方式。

外部碎片：还没有被分配出去（不属于任何进程），但由于太小了，无法分配给新进程的内存空闲区域；一般见于动态分配方式。

### 如何消除内存碎片？

对于外部碎片可用采用**紧凑技术**消除，就是操作系统定期对进程内存空间进行移动。

解决内部碎片的方案是**内存交换**。通过内存中程序交换到磁盘上，然后从磁盘读回到内存，重新整理空间。

### 冯诺依曼结构有哪些模块？

冯诺依曼架构：运算器，存储器，控制器还有输入输出设备。

冯诺依曼和哈佛的最大区别是，哈佛架构将数据和程序分开来。

### 服务器高并发解决方案。

 应用数据和静态资源分离。应用数据对应于热数据，而静态资源对应冷数据。对应的分为静态资源服务器和用户数据服务器；

客户端缓存，因为效率最高，消耗资源最小的就是纯静态的html页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用ajax异步请求获取动态数据。

集群和分布式：大量分布式集群来代替昂贵的高性能服务器，比如Hadoop集群，Ceph集群等；

反向代理：在访问服务器时候，服务器通过别的服务器获取资源或者返回结果。



---



# 外部设备

### 常见的<u>磁盘调度</u>算法

影响读写一个磁盘块的时间因素有：

1. 寻道时间（磁头移动到目标磁道）
2. 旋转时间（主轴转动盘面，使磁头移动到合适的扇区上）
3. 数据传输时间

其中寻道时间最长。

1. FCFS

按照磁盘请求的顺序进行调度。优点是公平简单，但平均寻道时间长。

2. 最短寻道时间优先SSTF

优先调度与当前磁头所在磁道距离最近的磁道。虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。

3. 电梯扫描算法SCAN

磁头总是向一个方向移动，直到该方向没有请求。

扫描算法的平均响应时间比最短寻找楼层时间优先算法长，但是响应时间方差比最短寻找楼层时间优先算法小，从统计学角度来讲，扫描算法要比最短寻找楼层时间优先算法稳定。







### 磁盘空间分配的方式

连续分配、链接分配和索引分配

**连续分配**：每个文件在磁盘中占有连续的块，这样便于顺序访问和直接访问，磁盘寻道时间短。但这样需要事先知道文件分配空间的大小。

**链接分配**：每个文件是磁盘块的链表，可以充分利用磁盘空闲空间。但寻道时间较长，不支持直接访问。此外链表的指针也会占用空间。

**索引分配**：将指针聚集在一起，组成一个索引块。索引分配支持直接访问，并且没有外部碎片问题，因为磁盘的任何空闲块可以满足更多空间的请求。然而，索引分配确实浪费空间。索引块指针的开销通常大于链接分配的指针开销。考虑一下常见情况，即一个文件只有一块或两块。采用链接分配，每块只浪费一个指针的空间。采用索引分配，即使只有一个或两个指针是非空的，也必须分配一个完整的索引块。

这一点提出了一个问题：索引块应为多大？每个文件必须有一个索引块，因此需要索引块尽可能小。然而，如果索引块太小，它不能为大的文件存储足够多的指针。因此，必须采取一种机制，以处理这个问题。此目的的机制包括：

- 链接方案：一个索引块通常为一个磁盘块。因此，它本身能直接读写。为了支持大的文件，可以将多个索引块链接起来。例如，一个索引块可以包括一个含有文件名的头部和一组头 100 个磁盘块的地址。下一个地址（索引块的最后一个字）为 null（对于小文件），或者另一个索引块的指针（对于大文件）。
- 多级索引：链接表示的一种变种是，通过第一级索引块指向一组第二级的索引块，它又指向文件块。当访问一块时，操作系统通过第一级索引查找第二级索引块，再采 用这个块查找所需的数据块。这种做法可以持续到第三级或第四级，具体取决于最大文件大小。对于 4096 字节的块，可以在索引块中存入 1024 个 4 字节的指针。两级索引支持 1 048 576 个数据块和 4GB 的最大文件。
- 组合方案：用于基于 UNIX 的文件系统，将索引块的前几个（如 15）指针存在文件的 inode 中。这些指针的前 12 个指向直接块；即它们包含存储文件数据的块的地址。因此，小的文件（不超过 12 块）不需要单独的索引块。如果块大小为 4KB，则不超过 48KB 的数据可以直接访问。接下来的 3 个指针指向间接块。第一个指向一级间接块。一级间接块为索引块，它包含的不是数据，而是真正包含数据的块的地址。第二个指向二级间接块，它包含了一个块的地址，而这个块内的地址指向了一些块，这些块中又包含了指向真实数据块的指针。最后一个指针为三级间接块指针。图 5 显示了一个 UNIX 的 inode。

![UNIX的inode](操作系统(阿秀版)/2-1Q112104552123.gif)

采用这种方法，一个文件的块数可以超过许多操作系统所用的 4 字节的文件指针所能访问的空间。32 位指针只能访问 232 字节，或 4GB。许多 UNIX 和 Linux 现在支持 64 位的 文件指针。这样的指针允许文件和文件系统为数艾字节。ZFS 文件系统支持 128 位的文件 指针。

索引分配方案与链接分配一样在性能方面有所欠缺。尤其是，虽然索引块可以缓存在内存中，但是数据块可能分布在整个卷上。

有些系统将连续分配和索引分配组合起来：对于小文件（只有 3 或 4 块的）采用连续分配；当文件增大时，自动切换到索引分配。由于大多数文件较小，小文件的连续分配的效率又高，所以平均性能还是相当不错的。







### RAID技术

RAID 0： 将数据按照条带化进行组织。

RAID1：将数据镜像复制一份。

RAID1+0：将数据镜像并按照条带化组织。

RAID0+1：将数据按照条带化组织并对条带镜像。

RAID2：带海明校验。

RAID3：带奇偶校验，使用单块校验盘。

RAID4：它对数据访问是按磁盘来的。RAID3一次一横条，而RAID4一次一竖条。

RAID5：奇偶校验码存在于所有磁盘上，常用round-robin布局。

RAID6：有两种校验码，能容2错。

![RAID 0+1 和 RAID 1+0](操作系统(阿秀版)/2-1Q109160349241.gif)

RAID技术存在的问题：

RAID并不总是保证数据对操作系统和使用者是可用的。

例如，文件指针可能是错的，或文件结构内的指针可能是错的。如果没有正确恢复，则不完整的写入会导致数据损坏。一些其他进程也会偶然写出文件系统的结构。RAID 防范物理媒介错误，但不是其他硬件和软件错误。与软件和硬件错误一样，系统数据潜在危险也有许多。

Solaris ZFS 文件系统采用创新方法来解决这些问题，即采用校验和，这是用于验证数据完整性的一种技术。ZFS 维护所有块（包括数据和元数据）的内部校验和。这些校验和没有与正在进行校验的块放在一起；而是与块的指针放在一起（见图 3）

![ZFS校验所有的元数据与数据](操作系统(阿秀版)/2-1Q109160A9106.gif)

考虑一个信息节点（存储文件系统元数据的结构），带有数据指针。每个数据块的校验和位于 inode 内，如果数据有问题，则校验和会不正确，并且文件系统会知道它。如果数据是镜像的，有一个块具有正确的校验和，并且另有一个块具有不正确的校验和，那么ZFS会自动采用好的块来更新错误的块。


类似地，指向 inode 的目录条目具有 inode 的校验和。当访问目录时，inode 的任何问题会检测到。所有 ZFS 结构都会进行校验和，以便提供比 RAID 磁盘集或标准文件系统更高级别的一致性、错误检测和错误纠正。因为 ZFS 的整体性能非常快，校验和计算与额外块读-改-写周期的额外开销不是明显的。

大多数的 RAID 实现的另一个问题是缺乏灵活性。考虑一个具有 20 个磁盘的存储阵列，它分为 4 组，每组有 5 个磁盘。5 个磁盘的组为 RAID 级别 5。因此，有 4 个单独的卷，每个都有文件系统。但是如果文件太大以致于不适合 5 个磁盘的组，怎么办？如果另一个文件系统需要很少的空间，怎么办？如果事先已经知道这些因素，则可以正确分配磁盘和卷。然而，很多时候磁盘的使用和需求随时间而变化。

即使存储阵列允许 20 个磁盘的集合创建成一个大的 RAID 集，其他问题可能出现。多个各种大小的卷可以创建在这个集上。但是有的卷管理器不允许我们改变卷的大小。在这种情况下，会有与上述相同的不匹配文件系统大小的问题。有些卷管理器允许更改大小，但是有些文件系统不允许文件系统生长或收缩。卷可以更改大小，但是文件系统需要重建以利用这些改变。

ZFS 将文件系统管理和卷管理组合到一起，比这些功能的传统分开提供更强的功能。磁盘，或磁盘分区，通过 RAID 集组成存储池。每个池可以容纳一个或多个 ZFS 文件系统。整个池的可用空间可用于该池的所有文件系统。

![img](操作系统(阿秀版)/2-1Q109160P14c.gif)



---

# 勘误@阿秀

#### [11、动态分区分配算法有哪几种？可以分别说说吗？](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=11、动态分区分配算法有哪几种？可以分别说说吗？)

PPT重叠了

#### [14、一个程序从开始运行到结束的完整过程，你能说出来多少？](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=14、一个程序从开始运行到结束的完整过程，你能说出来多少？)

应该是一个程序从文本到可执行文件要经历哪些过程？

#### [15、通过例子讲解逻辑地址转换为物理地址的基本过程](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=15、通过例子讲解逻辑地址转换为物理地址的基本过程)

PPT重叠了

#### [19、进程间通信有哪几种方式？把你知道的都说出来](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=19、进程间通信有哪几种方式？把你知道的都说出来)

失败范湖范围-1

#### [41、Windows和Linux环境下内存分布情况](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=41、windows和linux环境下内存分布情况)

.bss段

#### [57、可能是最全的页面置换算法总结了](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=57、可能是最全的页面置换算法总结了)

建议加一下缓存置换算法，比如LFU。很多人，比如我，经常把LRU和LFU搞混。

#### [59、死锁相关问题大总结，超全！](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=59、死锁相关问题大总结，超全！)

死锁应该是两个进程之间产生的。建议参考：https://baike.baidu.com/item/%E6%AD%BB%E9%94%81/2196938#2
